version: "3.3"
services:
  text-generation-webui:
    # build:
    #   context: .
    #   args:
    #     # specify which cuda version your card supports: https://developer.nvidia.com/cuda-gpus
    #     TORCH_CUDA_ARCH_LIST: ${TORCH_CUDA_ARCH_LIST:-8.9}
    # WEBUI_VERSION: ${WEBUI_VERSION:-HEAD}
    image: atinoda/text-generation-webui:default
    environment:
      - HF_TOKEN=${HF_TOKEN:-NONE}
      - EXTRA_LAUNCH_ARGS="--listen --verbose --extensions openai" # Custom launch args (e.g., --model MODEL_NAME)
    ports:
      - 7860:7860
      - 5000:5000
      - 5005:5005
      - 5001:5001
    stdin_open: true
    tty: true
    volumes:
      - ./characters:/app/characters
      - ./extensions:/app/extensions
      - ./loras:/app/loras
      - ./models:/app/models
      - ./presets:/app/presets
      - ./prompts:/app/prompts
      - ./training:/app/training
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
